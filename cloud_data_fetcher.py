#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœŸè´§æŒä»“åˆ†æç³»ç»Ÿ - äº‘ç«¯æ•°æ®è·å–æ¨¡å—
ä¸“é—¨è§£å†³Streamlit Cloudç¯å¢ƒä¸‹çš„æ•°æ®è·å–é—®é¢˜
ä½œè€…ï¼š7haoge
é‚®ç®±ï¼š953534947@qq.com
"""

import streamlit as st
import pandas as pd
import numpy as np
import requests
import time
import os
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import warnings
warnings.filterwarnings('ignore')

class CloudDataFetcher:
    """äº‘ç«¯æ•°æ®è·å–å™¨ - ä¸“é—¨å¤„ç†äº‘ç«¯ç¯å¢ƒçš„æ•°æ®è·å–é—®é¢˜"""
    
    def __init__(self):
        self.session = self.create_session()
        self.max_retries = 3
        self.timeout = 30
        self.delay_between_requests = 2  # è¯·æ±‚é—´éš”
        
    def create_session(self):
        """åˆ›å»ºä¼˜åŒ–çš„è¯·æ±‚ä¼šè¯"""
        session = requests.Session()
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        })
        return session
    
    def safe_akshare_call(self, func, *args, **kwargs):
        """å®‰å…¨çš„akshareè°ƒç”¨ï¼ŒåŒ…å«é‡è¯•æœºåˆ¶å’Œè¶…æ—¶æ§åˆ¶"""
        for attempt in range(self.max_retries):
            try:
                # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
                if attempt > 0:
                    time.sleep(self.delay_between_requests * attempt)
                
                # ä½¿ç”¨æ›´çŸ­çš„è¶…æ—¶æ—¶é—´ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå¹¿æœŸæ‰€
                import signal
                
                def timeout_handler(signum, frame):
                    raise TimeoutError("è¯·æ±‚è¶…æ—¶")
                
                # è®¾ç½®è¶…æ—¶ä¿¡å·ï¼ˆä»…åœ¨éWindowsç³»ç»Ÿï¼‰
                try:
                    signal.signal(signal.SIGALRM, timeout_handler)
                    signal.alarm(20)  # 20ç§’è¶…æ—¶
                except:
                    pass  # Windowsç³»ç»Ÿä¸æ”¯æŒSIGALRM
                
                result = func(*args, **kwargs)
                
                # å–æ¶ˆè¶…æ—¶ä¿¡å·
                try:
                    signal.alarm(0)
                except:
                    pass
                
                if result is not None:
                    return result
                    
            except TimeoutError:
                st.warning(f"è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1}/{self.max_retries})")
                if attempt == self.max_retries - 1:
                    st.error("å¤šæ¬¡è¶…æ—¶ï¼Œè·³è¿‡æ­¤æ•°æ®æº")
                continue
                
            except Exception as e:
                error_msg = str(e)
                if attempt == self.max_retries - 1:
                    st.warning(f"æ•°æ®è·å–å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retries}): {error_msg}")
                else:
                    st.info(f"é‡è¯•ä¸­... (å°è¯• {attempt + 1}/{self.max_retries})")
                
                # ç‰¹å®šé”™è¯¯çš„å¤„ç†
                if "timeout" in error_msg.lower():
                    time.sleep(5)  # è¶…æ—¶é”™è¯¯ç­‰å¾…æ›´é•¿æ—¶é—´
                elif "rate limit" in error_msg.lower():
                    time.sleep(10)  # é¢‘ç‡é™åˆ¶ç­‰å¾…æ›´é•¿æ—¶é—´
                elif "connection" in error_msg.lower():
                    time.sleep(3)  # è¿æ¥é”™è¯¯ç­‰å¾…
                    
        return None
    
    def fetch_position_data_with_fallback(self, trade_date: str, progress_callback=None) -> bool:
        """è·å–æŒä»“æ•°æ®ï¼ŒåŒ…å«å¤‡ç”¨æ–¹æ¡ˆ"""
        
        # å°è¯•å¯¼å…¥akshare
        try:
            import akshare as ak
        except ImportError:
            st.error("akshareæœªå®‰è£…ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
            return False
        
        success_count = 0
        total_exchanges = 5
        
        # äº¤æ˜“æ‰€é…ç½® - æŒ‰æˆåŠŸç‡æ’åºï¼Œå¹¿æœŸæ‰€æ”¾åœ¨æœ€å
        exchanges = [
            {
                "name": "å¤§å•†æ‰€",
                "func": ak.get_dce_rank_table,
                "filename": "å¤§å•†æ‰€æŒä»“.xlsx",
                "args": {"date": trade_date},
                "timeout": 30
            },
            {
                "name": "ä¸­é‡‘æ‰€", 
                "func": ak.get_cffex_rank_table,
                "filename": "ä¸­é‡‘æ‰€æŒä»“.xlsx",
                "args": {"date": trade_date},
                "timeout": 30
            },
            {
                "name": "éƒ‘å•†æ‰€",
                "func": ak.get_czce_rank_table,
                "filename": "éƒ‘å•†æ‰€æŒä»“.xlsx", 
                "args": {"date": trade_date},
                "timeout": 30
            },
            {
                "name": "ä¸ŠæœŸæ‰€",
                "func": ak.get_shfe_rank_table,
                "filename": "ä¸ŠæœŸæ‰€æŒä»“.xlsx",
                "args": {"date": trade_date},
                "timeout": 30
            },
            {
                "name": "å¹¿æœŸæ‰€",
                "func": ak.futures_gfex_position_rank,
                "filename": "å¹¿æœŸæ‰€æŒä»“.xlsx",
                "args": {"date": trade_date},
                "timeout": 15  # å¹¿æœŸæ‰€ä½¿ç”¨æ›´çŸ­çš„è¶…æ—¶æ—¶é—´
            }
        ]
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        data_dir = "data"
        os.makedirs(data_dir, exist_ok=True)
        
        for i, exchange in enumerate(exchanges):
            if progress_callback:
                progress = i / total_exchanges * 0.6
                progress_callback(f"æ­£åœ¨è·å– {exchange['name']} æ•°æ®...", progress)
            
            try:
                st.info(f"ğŸ”„ æ­£åœ¨è·å– {exchange['name']} æ•°æ®...")
                
                # ç‰¹æ®Šå¤„ç†å¹¿æœŸæ‰€
                if exchange['name'] == 'å¹¿æœŸæ‰€':
                    st.warning("âš ï¸ å¹¿æœŸæ‰€æ•°æ®è·å–å¯èƒ½è¾ƒæ…¢ï¼Œæ­£åœ¨å°è¯•...")
                    
                    # ä½¿ç”¨æ›´çŸ­çš„è¶…æ—¶å’Œæ›´å°‘çš„é‡è¯•æ¬¡æ•°
                    original_retries = self.max_retries
                    self.max_retries = 2  # å¹¿æœŸæ‰€åªé‡è¯•2æ¬¡
                
                # ä½¿ç”¨å®‰å…¨è°ƒç”¨
                start_time = time.time()
                data_dict = self.safe_akshare_call(exchange['func'], **exchange['args'])
                end_time = time.time()
                
                # æ¢å¤åŸå§‹é‡è¯•æ¬¡æ•°
                if exchange['name'] == 'å¹¿æœŸæ‰€':
                    self.max_retries = original_retries
                
                if data_dict:
                    # ä¿å­˜æ•°æ®
                    save_path = os.path.join(data_dir, exchange['filename'])
                    with pd.ExcelWriter(save_path, engine='openpyxl') as writer:
                        for sheet_name, df in data_dict.items():
                            # æ¸…ç†sheetåç§°
                            clean_name = sheet_name[:31].replace("/", "-").replace("*", "")
                            df.to_excel(writer, sheet_name=clean_name, index=False)
                    
                    st.success(f"âœ… {exchange['name']} æ•°æ®è·å–æˆåŠŸ (è€—æ—¶: {end_time - start_time:.1f}ç§’)")
                    success_count += 1
                else:
                    if exchange['name'] == 'å¹¿æœŸæ‰€':
                        st.warning(f"âš ï¸ {exchange['name']} æ•°æ®è·å–å¤±è´¥ï¼ˆäº‘ç«¯ç¯å¢ƒé™åˆ¶ï¼‰ï¼Œä½†ä¸å½±å“åˆ†æ")
                    else:
                        st.warning(f"âš ï¸ {exchange['name']} æ•°æ®è·å–å¤±è´¥ï¼Œä½†ä¸å½±å“å…¶ä»–äº¤æ˜“æ‰€")
                    
            except Exception as e:
                error_msg = str(e)
                if exchange['name'] == 'å¹¿æœŸæ‰€':
                    st.warning(f"âš ï¸ {exchange['name']} æ•°æ®è·å–å¤±è´¥ï¼ˆäº‘ç«¯ç¯å¢ƒé™åˆ¶ï¼‰: {error_msg}")
                else:
                    st.warning(f"âš ï¸ {exchange['name']} æ•°æ®è·å–å¤±è´¥: {error_msg}")
                continue
            
            # æ·»åŠ è¯·æ±‚é—´éš”ï¼Œå¹¿æœŸæ‰€åç­‰å¾…æ›´é•¿æ—¶é—´
            if exchange['name'] == 'å¹¿æœŸæ‰€':
                time.sleep(self.delay_between_requests * 2)
            else:
                time.sleep(self.delay_between_requests)
        
        if progress_callback:
            progress_callback("æŒä»“æ•°æ®è·å–å®Œæˆ", 0.6)
        
        # å¦‚æœè‡³å°‘æœ‰3ä¸ªäº¤æ˜“æ‰€æˆåŠŸï¼Œå°±è®¤ä¸ºæˆåŠŸ
        if success_count >= 3:
            st.info(f"âœ… æˆåŠŸè·å– {success_count}/{total_exchanges} ä¸ªäº¤æ˜“æ‰€æ•°æ®ï¼Œå¯ä»¥è¿›è¡Œåˆ†æ")
            return True
        elif success_count > 0:
            st.warning(f"âš ï¸ ä»…è·å–åˆ° {success_count}/{total_exchanges} ä¸ªäº¤æ˜“æ‰€æ•°æ®ï¼Œåˆ†æç»“æœå¯èƒ½ä¸å®Œæ•´")
            return True
        else:
            st.error("âŒ æ‰€æœ‰äº¤æ˜“æ‰€æ•°æ®è·å–å¤±è´¥")
            return False
    
    def fetch_price_data_with_fallback(self, trade_date: str, progress_callback=None) -> pd.DataFrame:
        """è·å–æœŸè´§è¡Œæƒ…æ•°æ®ï¼ŒåŒ…å«æ™ºèƒ½è‡ªåŠ¨è·³è¿‡åŠŸèƒ½"""
        
        try:
            import akshare as ak
        except ImportError:
            st.error("akshareæœªå®‰è£…ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
            return pd.DataFrame()
        
        # è¡Œæƒ…æ•°æ®äº¤æ˜“æ‰€é…ç½® - åŒ…å«æ‰€æœ‰äº¤æ˜“æ‰€ï¼Œå¢å¼ºè¶…æ—¶å¤„ç†
        price_exchanges = [
            {"market": "DCE", "name": "å¤§å•†æ‰€", "timeout": 30},
            {"market": "CFFEX", "name": "ä¸­é‡‘æ‰€", "timeout": 30},
            {"market": "CZCE", "name": "éƒ‘å•†æ‰€", "timeout": 30},
            {"market": "SHFE", "name": "ä¸ŠæœŸæ‰€", "timeout": 30},
            {"market": "GFEX", "name": "å¹¿æœŸæ‰€", "timeout": 15},  # å¹¿æœŸæ‰€ä½¿ç”¨æ›´çŸ­è¶…æ—¶ï¼Œé‡åˆ°é—®é¢˜è‡ªåŠ¨è·³è¿‡
        ]
        
        all_data = []
        success_count = 0
        
        for i, exchange in enumerate(price_exchanges):
            if progress_callback:
                progress = 0.6 + (i / len(price_exchanges)) * 0.2
                progress_callback(f"æ­£åœ¨è·å– {exchange['name']} è¡Œæƒ…æ•°æ®...", progress)
            
            try:
                st.info(f"ğŸ”„ æ­£åœ¨è·å– {exchange['name']} è¡Œæƒ…æ•°æ®...")
                
                # è®°å½•å¼€å§‹æ—¶é—´
                start_time = time.time()
                
                # å¯¹å¹¿æœŸæ‰€ä½¿ç”¨å¢å¼ºçš„è¶…æ—¶æ§åˆ¶
                if exchange['name'] == 'å¹¿æœŸæ‰€':
                    st.info("âš ï¸ å¹¿æœŸæ‰€æ•°æ®è·å–ä¸­ï¼Œå¦‚é‡é—®é¢˜å°†è‡ªåŠ¨è·³è¿‡...")
                    
                    try:
                        # ä½¿ç”¨çº¿ç¨‹å’Œä¸¥æ ¼è¶…æ—¶æ§åˆ¶
                        import threading
                        import queue
                        
                        result_queue = queue.Queue()
                        
                        def fetch_gfex_data():
                            try:
                                result = self.safe_akshare_call(
                                    ak.get_futures_daily,
                                    start_date=trade_date,
                                    end_date=trade_date,
                                    market=exchange["market"]
                                )
                                result_queue.put(('success', result))
                            except Exception as e:
                                result_queue.put(('error', str(e)))
                        
                        # å¯åŠ¨è·å–çº¿ç¨‹
                        fetch_thread = threading.Thread(target=fetch_gfex_data)
                        fetch_thread.daemon = True
                        fetch_thread.start()
                        
                        # ç­‰å¾…ç»“æœï¼Œä½¿ç”¨é…ç½®çš„è¶…æ—¶æ—¶é—´
                        fetch_thread.join(timeout=exchange.get('timeout', 15))
                        
                        if fetch_thread.is_alive():
                            # è¶…æ—¶äº†ï¼Œè‡ªåŠ¨è·³è¿‡
                            st.warning(f"âš ï¸ {exchange['name']} æ•°æ®è·å–è¶…æ—¶({exchange.get('timeout', 15)}ç§’)ï¼Œè‡ªåŠ¨è·³è¿‡")
                            continue
                        
                        # è·å–ç»“æœ
                        try:
                            status, df = result_queue.get_nowait()
                            if status == 'error':
                                raise Exception(df)
                        except queue.Empty:
                            st.warning(f"âš ï¸ {exchange['name']} æ•°æ®è·å–æ— å“åº”ï¼Œè‡ªåŠ¨è·³è¿‡")
                            continue
                            
                    except Exception as e:
                        st.warning(f"âš ï¸ {exchange['name']} æ•°æ®è·å–å¤±è´¥ï¼Œè‡ªåŠ¨è·³è¿‡: {str(e)}")
                        continue
                else:
                    # å…¶ä»–äº¤æ˜“æ‰€ä½¿ç”¨æ ‡å‡†è·å–æ–¹å¼
                    df = self.safe_akshare_call(
                        ak.get_futures_daily,
                        start_date=trade_date,
                        end_date=trade_date,
                        market=exchange["market"]
                    )
                
                end_time = time.time()
                elapsed_time = end_time - start_time
                
                if df is not None and not df.empty:
                    df['exchange'] = exchange["name"]
                    all_data.append(df)
                    st.success(f"âœ… {exchange['name']} è¡Œæƒ…æ•°æ®è·å–æˆåŠŸ (è€—æ—¶: {elapsed_time:.1f}ç§’)")
                    success_count += 1
                else:
                    st.warning(f"âš ï¸ {exchange['name']} è¡Œæƒ…æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡")
                    
            except Exception as e:
                error_msg = str(e)
                elapsed_time = time.time() - start_time if 'start_time' in locals() else 0
                st.warning(f"âš ï¸ {exchange['name']} è¡Œæƒ…æ•°æ®è·å–å¤±è´¥ï¼Œè·³è¿‡: {error_msg}")
                continue
            
            # æ·»åŠ è¯·æ±‚é—´éš”
            time.sleep(self.delay_between_requests)
        
        if progress_callback:
            progress_callback("è¡Œæƒ…æ•°æ®è·å–å®Œæˆ", 0.8)
        
        # æ˜¾ç¤ºè·å–ç»“æœç»Ÿè®¡
        total_exchanges = len(price_exchanges)
        if success_count >= 3:
            st.info(f"âœ… æˆåŠŸè·å– {success_count}/{total_exchanges} ä¸ªäº¤æ˜“æ‰€è¡Œæƒ…æ•°æ®")
        elif success_count > 0:
            st.warning(f"âš ï¸ ä»…è·å–åˆ° {success_count}/{total_exchanges} ä¸ªäº¤æ˜“æ‰€è¡Œæƒ…æ•°æ®")
        else:
            st.warning("âš ï¸ æœªèƒ½è·å–åˆ°ä»»ä½•è¡Œæƒ…æ•°æ®ï¼Œå°†ä½¿ç”¨åŸºç¡€åˆ†æ")
        
        return pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()
    
    def create_demo_data(self, trade_date: str) -> bool:
        """åˆ›å»ºæ¼”ç¤ºæ•°æ®ï¼ˆå½“æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥æ—¶ï¼‰"""
        st.warning("âš ï¸ æ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•è®¿é—®ï¼Œæ­£åœ¨åˆ›å»ºæ¼”ç¤ºæ•°æ®...")
        
        data_dir = "data"
        os.makedirs(data_dir, exist_ok=True)
        
        # åˆ›å»ºæ¼”ç¤ºæŒä»“æ•°æ®
        demo_contracts = ['èºçº¹é’¢2501', 'é“çŸ¿çŸ³2501', 'è±†ç²•2501', 'ç‰ç±³2501', 'ç™½ç³–2501']
        
        for exchange_name in ['å¤§å•†æ‰€', 'ä¸­é‡‘æ‰€', 'éƒ‘å•†æ‰€', 'ä¸ŠæœŸæ‰€', 'å¹¿æœŸæ‰€']:
            filename = f"{exchange_name}æŒä»“.xlsx"
            save_path = os.path.join(data_dir, filename)
            
            # åˆ›å»ºæ¼”ç¤ºæ•°æ®
            demo_data = {}
            for contract in demo_contracts:
                # ç”Ÿæˆéšæœºä½†åˆç†çš„æŒä»“æ•°æ®
                np.random.seed(hash(contract + trade_date) % 2**32)
                
                data = []
                for i in range(20):  # å‰20å
                    data.append({
                        'long_party_name': f'æœŸè´§å…¬å¸{i+1}',
                        'long_open_interest': np.random.randint(1000, 50000),
                        'long_open_interest_chg': np.random.randint(-5000, 5000),
                        'short_party_name': f'æœŸè´§å…¬å¸{i+1}',
                        'short_open_interest': np.random.randint(1000, 50000),
                        'short_open_interest_chg': np.random.randint(-5000, 5000),
                    })
                
                demo_data[contract] = pd.DataFrame(data)
            
            # ä¿å­˜æ¼”ç¤ºæ•°æ®
            with pd.ExcelWriter(save_path, engine='openpyxl') as writer:
                for sheet_name, df in demo_data.items():
                    df.to_excel(writer, sheet_name=sheet_name, index=False)
        
        st.info("âœ… æ¼”ç¤ºæ•°æ®åˆ›å»ºå®Œæˆï¼Œæ‚¨å¯ä»¥ä½“éªŒç³»ç»ŸåŠŸèƒ½")
        return True
    
    def diagnose_network_issues(self):
        """è¯Šæ–­ç½‘ç»œé—®é¢˜"""
        st.subheader("ğŸ” ç½‘ç»œè¯Šæ–­")
        
        # æµ‹è¯•åŸºæœ¬ç½‘ç»œè¿æ¥
        test_urls = [
            ("ç™¾åº¦", "https://www.baidu.com"),
            ("æ–°æµª", "https://www.sina.com.cn"),
            ("akshareå®˜ç½‘", "https://akshare.akfamily.xyz")
        ]
        
        for name, url in test_urls:
            try:
                response = requests.get(url, timeout=10)
                if response.status_code == 200:
                    st.success(f"âœ… {name} è¿æ¥æ­£å¸¸")
                else:
                    st.warning(f"âš ï¸ {name} è¿æ¥å¼‚å¸¸ (çŠ¶æ€ç : {response.status_code})")
            except Exception as e:
                st.error(f"âŒ {name} è¿æ¥å¤±è´¥: {str(e)}")
        
        # æµ‹è¯•akshareå¯¼å…¥
        try:
            import akshare as ak
            st.success(f"âœ… akshare å¯¼å…¥æˆåŠŸ (ç‰ˆæœ¬: {getattr(ak, '__version__', 'æœªçŸ¥')})")
        except ImportError:
            st.error("âŒ akshare å¯¼å…¥å¤±è´¥")
        
        # æä¾›è§£å†³å»ºè®®
        st.markdown("""
        ### ğŸ’¡ è§£å†³å»ºè®®
        
        å¦‚æœæ•°æ®è·å–å¤±è´¥ï¼Œå¯èƒ½çš„åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š
        
        1. **ç½‘ç»œé™åˆ¶**: Streamlit Cloudå¯èƒ½é™åˆ¶æŸäº›å¤–éƒ¨APIè®¿é—®
           - è§£å†³æ–¹æ¡ˆ: ä½¿ç”¨æ¼”ç¤ºæ•°æ®ä½“éªŒåŠŸèƒ½
        
        2. **APIé¢‘ç‡é™åˆ¶**: akshareçš„æ•°æ®æºå¯èƒ½æœ‰è®¿é—®é¢‘ç‡é™åˆ¶
           - è§£å†³æ–¹æ¡ˆ: ç­‰å¾…å‡ åˆ†é’Ÿåé‡è¯•
        
        3. **æ•°æ®æºç»´æŠ¤**: äº¤æ˜“æ‰€æ•°æ®æºå¯èƒ½åœ¨ç»´æŠ¤
           - è§£å†³æ–¹æ¡ˆ: é€‰æ‹©å…¶ä»–äº¤æ˜“æ—¥æœŸ
        
        4. **äº‘ç«¯ç¯å¢ƒé™åˆ¶**: æŸäº›äº‘ç«¯ç¯å¢ƒå¯¹å¤–éƒ¨è¯·æ±‚æœ‰é™åˆ¶
           - è§£å†³æ–¹æ¡ˆ: æœ¬åœ°è¿è¡Œæˆ–ä½¿ç”¨æ¼”ç¤ºæ¨¡å¼
        """)

    def fetch_position_data_skip_gfex(self, trade_date: str, progress_callback=None) -> bool:
        """è·å–æŒä»“æ•°æ®ï¼Œè·³è¿‡å¹¿æœŸæ‰€ï¼ˆäº‘ç«¯ç¯å¢ƒä¸“ç”¨ï¼‰"""
        
        # å°è¯•å¯¼å…¥akshare
        try:
            import akshare as ak
        except ImportError:
            st.error("akshareæœªå®‰è£…ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
            return False
        
        success_count = 0
        total_exchanges = 4  # ä¸åŒ…å«å¹¿æœŸæ‰€
        
        # äº¤æ˜“æ‰€é…ç½® - ä¸åŒ…å«å¹¿æœŸæ‰€
        exchanges = [
            {
                "name": "å¤§å•†æ‰€",
                "func": ak.get_dce_rank_table,
                "filename": "å¤§å•†æ‰€æŒä»“.xlsx",
                "args": {"date": trade_date}
            },
            {
                "name": "ä¸­é‡‘æ‰€", 
                "func": ak.get_cffex_rank_table,
                "filename": "ä¸­é‡‘æ‰€æŒä»“.xlsx",
                "args": {"date": trade_date}
            },
            {
                "name": "éƒ‘å•†æ‰€",
                "func": ak.get_czce_rank_table,
                "filename": "éƒ‘å•†æ‰€æŒä»“.xlsx", 
                "args": {"date": trade_date}
            },
            {
                "name": "ä¸ŠæœŸæ‰€",
                "func": ak.get_shfe_rank_table,
                "filename": "ä¸ŠæœŸæ‰€æŒä»“.xlsx",
                "args": {"date": trade_date}
            }
        ]
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        data_dir = "data"
        os.makedirs(data_dir, exist_ok=True)
        
        st.info("ğŸš€ ä½¿ç”¨å¿«é€Ÿæ¨¡å¼ï¼šè·³è¿‡å¹¿æœŸæ‰€æ•°æ®è·å–")
        
        for i, exchange in enumerate(exchanges):
            if progress_callback:
                progress = i / total_exchanges * 0.6
                progress_callback(f"æ­£åœ¨è·å– {exchange['name']} æ•°æ®...", progress)
            
            try:
                st.info(f"ğŸ”„ æ­£åœ¨è·å– {exchange['name']} æ•°æ®...")
                
                # ä½¿ç”¨å®‰å…¨è°ƒç”¨
                start_time = time.time()
                data_dict = self.safe_akshare_call(exchange['func'], **exchange['args'])
                end_time = time.time()
                
                if data_dict:
                    # ä¿å­˜æ•°æ®
                    save_path = os.path.join(data_dir, exchange['filename'])
                    with pd.ExcelWriter(save_path, engine='openpyxl') as writer:
                        for sheet_name, df in data_dict.items():
                            # æ¸…ç†sheetåç§°
                            clean_name = sheet_name[:31].replace("/", "-").replace("*", "")
                            df.to_excel(writer, sheet_name=clean_name, index=False)
                    
                    st.success(f"âœ… {exchange['name']} æ•°æ®è·å–æˆåŠŸ (è€—æ—¶: {end_time - start_time:.1f}ç§’)")
                    success_count += 1
                else:
                    st.warning(f"âš ï¸ {exchange['name']} æ•°æ®è·å–å¤±è´¥ï¼Œä½†ä¸å½±å“å…¶ä»–äº¤æ˜“æ‰€")
                    
            except Exception as e:
                st.warning(f"âš ï¸ {exchange['name']} æ•°æ®è·å–å¤±è´¥: {str(e)}")
                continue
            
            # æ·»åŠ è¯·æ±‚é—´éš”
            time.sleep(self.delay_between_requests)
        
        # åˆ›å»ºç©ºçš„å¹¿æœŸæ‰€æ–‡ä»¶ä»¥ä¿æŒå…¼å®¹æ€§
        gfex_path = os.path.join(data_dir, "å¹¿æœŸæ‰€æŒä»“.xlsx")
        empty_data = {'ç©ºæ•°æ®': pd.DataFrame({'è¯´æ˜': ['å¹¿æœŸæ‰€æ•°æ®å·²è·³è¿‡']})}
        with pd.ExcelWriter(gfex_path, engine='openpyxl') as writer:
            for sheet_name, df in empty_data.items():
                df.to_excel(writer, sheet_name=sheet_name, index=False)
        
        if progress_callback:
            progress_callback("æŒä»“æ•°æ®è·å–å®Œæˆï¼ˆå·²è·³è¿‡å¹¿æœŸæ‰€ï¼‰", 0.6)
        
        if success_count >= 3:
            st.success(f"âœ… æˆåŠŸè·å– {success_count}/{total_exchanges} ä¸ªä¸»è¦äº¤æ˜“æ‰€æ•°æ®ï¼ˆå·²è·³è¿‡å¹¿æœŸæ‰€ï¼‰")
            return True
        elif success_count > 0:
            st.warning(f"âš ï¸ ä»…è·å–åˆ° {success_count}/{total_exchanges} ä¸ªäº¤æ˜“æ‰€æ•°æ®")
            return True
        else:
            st.error("âŒ æ‰€æœ‰äº¤æ˜“æ‰€æ•°æ®è·å–å¤±è´¥")
            return False

    def fetch_position_data_with_auto_skip(self, trade_date: str, progress_callback=None) -> bool:
        """è·å–æŒä»“æ•°æ®ï¼Œä½¿ç”¨é›†æˆæ•°æ®è·å–å™¨ï¼ˆäº¤æ˜“å¸­ä½æ–¹æ³•ï¼‰"""
        
        # å°è¯•å¯¼å…¥akshare
        try:
            import akshare as ak
        except ImportError:
            st.error("akshareæœªå®‰è£…ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
            return False
        
        # ä¼˜å…ˆä½¿ç”¨é›†æˆæ•°æ®è·å–å™¨ï¼ˆäº¤æ˜“å¸­ä½å®Œæ•´é€»è¾‘ï¼‰
        try:
            from integrated_data_fetcher import IntegratedDataFetcher
            st.info("âœ… é›†æˆæ•°æ®è·å–å™¨å·²å¯ç”¨ï¼ˆä½¿ç”¨äº¤æ˜“å¸­ä½å®Œæ•´é€»è¾‘ï¼‰")
            return self._fetch_with_integrated_fetcher(trade_date, progress_callback)
        except ImportError:
            st.warning("âš ï¸ é›†æˆè·å–å™¨æœªæ‰¾åˆ°ï¼Œå°è¯•æ–°æµªè·å–å™¨...")
        except Exception as e:
            st.warning(f"âš ï¸ é›†æˆè·å–å™¨åŠ è½½å¤±è´¥: {str(e)[:50]}ï¼Œå°è¯•æ–°æµªè·å–å™¨...")
        
        # åå¤‡1ï¼šæ–°æµªè·å–å™¨
        try:
            from sina_position_fetcher import SinaPositionFetcher
            st.info("âœ… æ–°æµªæŒä»“æ•°æ®è·å–å™¨å·²å¯ç”¨")
            return self._fetch_with_sina_fetcher(trade_date, progress_callback)
        except ImportError:
            st.warning("âš ï¸ æ–°æµªè·å–å™¨æœªæ‰¾åˆ°ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•")
        except Exception as e:
            st.warning(f"âš ï¸ æ–°æµªè·å–å™¨åŠ è½½å¤±è´¥: {str(e)[:50]}ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•")
        
        # åå¤‡2ï¼šä¼ ç»Ÿæ–¹æ³•
        return self._fetch_with_traditional_method(trade_date, progress_callback)
    
    def _fetch_with_integrated_fetcher(self, trade_date: str, progress_callback=None) -> bool:
        """ä½¿ç”¨é›†æˆæ•°æ®è·å–å™¨è·å–æ•°æ®ï¼ˆäº¤æ˜“å¸­ä½å®Œæ•´é€»è¾‘ï¼šåœ¨çº¿è·å–åŸºå·®+æŒä»“ï¼‰"""
        from integrated_data_fetcher import IntegratedDataFetcher
        
        st.info("ğŸŒŸ ä½¿ç”¨é›†æˆæ•°æ®è·å–å™¨ï¼ˆåœ¨çº¿æ¨¡å¼ï¼šå®æ—¶è·å–åŸºå·®æ•°æ®â†’ä¸»åŠ›åˆçº¦â†’æŒä»“æ•°æ®ï¼‰")
        
        # ä½¿ç”¨åœ¨çº¿æ¨¡å¼åˆå§‹åŒ–
        fetcher = IntegratedDataFetcher("data", online_mode=True)
        
        # ä½¿ç”¨é›†æˆè·å–å™¨çš„ç»Ÿä¸€æ¥å£
        return fetcher.fetch_all_exchanges_data(trade_date, progress_callback)
    
    def _fetch_with_sina_fetcher(self, trade_date: str, progress_callback=None) -> bool:
        """ä½¿ç”¨æ–°æµªè·å–å™¨è·å–æ•°æ®"""
        from sina_position_fetcher import SinaPositionFetcher
        
        st.info("ğŸŒŸ ä½¿ç”¨æ–°æµªæŒä»“æ•°æ®è·å–å™¨ï¼ˆæ›´ç¨³å®šï¼‰")
        
        fetcher = SinaPositionFetcher("data")
        success_count = 0
        total_exchanges = 5
        
        exchange_list = ["å¤§å•†æ‰€", "ä¸­é‡‘æ‰€", "éƒ‘å•†æ‰€", "ä¸ŠæœŸæ‰€", "å¹¿æœŸæ‰€"]
        filenames = {
            "å¤§å•†æ‰€": "å¤§å•†æ‰€æŒä»“.xlsx",
            "ä¸­é‡‘æ‰€": "ä¸­é‡‘æ‰€æŒä»“.xlsx",
            "éƒ‘å•†æ‰€": "éƒ‘å•†æ‰€æŒä»“.xlsx",
            "ä¸ŠæœŸæ‰€": "ä¸ŠæœŸæ‰€æŒä»“.xlsx",
            "å¹¿æœŸæ‰€": "å¹¿æœŸæ‰€æŒä»“.xlsx"
        }
        
        for i, exchange_name in enumerate(exchange_list):
            if progress_callback:
                progress = i / total_exchanges * 0.6
                progress_callback(f"æ­£åœ¨è·å– {exchange_name} æ•°æ®ï¼ˆæ–°æµªAPIï¼‰...", progress)
            
            try:
                st.info(f"ğŸ”„ æ­£åœ¨è·å– {exchange_name} æ•°æ®ï¼ˆæ–°æµªAPIï¼‰...")
                
                # ä½¿ç”¨æ–°æµªè·å–å™¨
                data_dict = fetcher.fetch_exchange_data(exchange_name, trade_date)
                
                if data_dict:
                    # ä¿å­˜æ•°æ®
                    fetcher.save_to_excel(data_dict, filenames[exchange_name])
                    st.success(f"âœ… {exchange_name} æ•°æ®è·å–æˆåŠŸ")
                    success_count += 1
                else:
                    st.warning(f"âš ï¸ {exchange_name} æ•°æ®è·å–å¤±è´¥ï¼Œä½†ä¸å½±å“å…¶ä»–äº¤æ˜“æ‰€")
                    
            except Exception as e:
                st.warning(f"âš ï¸ {exchange_name} æ•°æ®è·å–å¤±è´¥: {str(e)[:50]}")
                continue
        
        if progress_callback:
            progress_callback("æŒä»“æ•°æ®è·å–å®Œæˆ", 0.6)
        
        if success_count >= 3:
            st.info(f"âœ… æˆåŠŸè·å– {success_count}/{total_exchanges} ä¸ªäº¤æ˜“æ‰€æ•°æ®")
            return True
        elif success_count > 0:
            st.warning(f"âš ï¸ ä»…è·å–åˆ° {success_count}/{total_exchanges} ä¸ªäº¤æ˜“æ‰€æ•°æ®")
            return True
        else:
            st.error("âŒ æ‰€æœ‰äº¤æ˜“æ‰€æ•°æ®è·å–å¤±è´¥")
            return False
    
    def _fetch_with_traditional_method(self, trade_date: str, progress_callback=None) -> bool:
        """ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•è·å–æ•°æ®ï¼ˆåå¤‡ï¼‰"""
        import akshare as ak
        
        st.info("ğŸ“Š ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•è·å–æ•°æ®")
        
        success_count = 0
        total_exchanges = 5
        
        # äº¤æ˜“æ‰€é…ç½® - ä½¿ç”¨å­—ç¬¦ä¸²åç§°ï¼Œå»¶è¿ŸåŠ è½½API
        exchanges = [
            {
                "name": "å¤§å•†æ‰€",
                "func_name": "get_dce_rank_table",
                "filename": "å¤§å•†æ‰€æŒä»“.xlsx",
                "args": {"date": trade_date},
                "timeout": 30
            },
            {
                "name": "ä¸­é‡‘æ‰€", 
                "func_name": "get_cffex_rank_table",
                "filename": "ä¸­é‡‘æ‰€æŒä»“.xlsx",
                "args": {"date": trade_date},
                "timeout": 30
            },
            {
                "name": "éƒ‘å•†æ‰€",
                "func_name": "get_czce_rank_table",
                "filename": "éƒ‘å•†æ‰€æŒä»“.xlsx", 
                "args": {"date": trade_date},
                "timeout": 30
            },
            {
                "name": "ä¸ŠæœŸæ‰€",
                "func_name": "get_shfe_rank_table",
                "filename": "ä¸ŠæœŸæ‰€æŒä»“.xlsx",
                "args": {"date": trade_date},
                "timeout": 30
            },
            {
                "name": "å¹¿æœŸæ‰€",
                "func_name": "futures_gfex_position_rank",
                "filename": "å¹¿æœŸæ‰€æŒä»“.xlsx",
                "args": {"date": trade_date},
                "timeout": 20  # å¹¿æœŸæ‰€ä½¿ç”¨æ›´çŸ­çš„è¶…æ—¶æ—¶é—´
            }
        ]
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        data_dir = "data"
        os.makedirs(data_dir, exist_ok=True)
        
        for i, exchange in enumerate(exchanges):
            if progress_callback:
                progress = i / total_exchanges * 0.6
                progress_callback(f"æ­£åœ¨è·å– {exchange['name']} æ•°æ®...", progress)
            
            try:
                st.info(f"ğŸ”„ æ­£åœ¨è·å– {exchange['name']} æ•°æ®...")
                
                # åŠ¨æ€è·å–APIå‡½æ•°
                func_name = exchange.get('func_name')
                if not hasattr(ak, func_name):
                    st.warning(f"âš ï¸ {exchange['name']}: API {func_name} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                    continue
                
                exchange_func = getattr(ak, func_name)
                
                # è®°å½•å¼€å§‹æ—¶é—´
                start_time = time.time()
                
                # ç‰¹æ®Šå¤„ç†å¹¿æœŸæ‰€ - ä½¿ç”¨æ›´ä¸¥æ ¼çš„è¶…æ—¶æ§åˆ¶
                if exchange['name'] == 'å¹¿æœŸæ‰€':
                    st.info("âš ï¸ å¹¿æœŸæ‰€æ•°æ®è·å–ä¸­ï¼Œå¦‚è¶…æ—¶å°†è‡ªåŠ¨è·³è¿‡...")
                    
                    # ä½¿ç”¨æ›´çŸ­çš„è¶…æ—¶å’Œæ›´å°‘çš„é‡è¯•æ¬¡æ•°
                    original_retries = self.max_retries
                    self.max_retries = 1  # å¹¿æœŸæ‰€åªå°è¯•1æ¬¡
                    
                    try:
                        # ä½¿ç”¨çº¿ç¨‹å’Œè¶…æ—¶æ§åˆ¶
                        import threading
                        import queue
                        
                        result_queue = queue.Queue()
                        
                        def fetch_data():
                            try:
                                result = self.safe_akshare_call(exchange_func, **exchange['args'])
                                result_queue.put(('success', result))
                            except Exception as e:
                                result_queue.put(('error', str(e)))
                        
                        # å¯åŠ¨è·å–çº¿ç¨‹
                        fetch_thread = threading.Thread(target=fetch_data)
                        fetch_thread.daemon = True
                        fetch_thread.start()
                        
                        # ç­‰å¾…ç»“æœï¼Œæœ€å¤šç­‰å¾…20ç§’
                        fetch_thread.join(timeout=20)
                        
                        if fetch_thread.is_alive():
                            # è¶…æ—¶äº†ï¼Œè‡ªåŠ¨è·³è¿‡
                            st.warning("âš ï¸ å¹¿æœŸæ‰€æ•°æ®è·å–è¶…æ—¶ï¼Œè‡ªåŠ¨è·³è¿‡ä»¥é¿å…å¡é¡¿")
                            self.max_retries = original_retries
                            
                            # åˆ›å»ºç©ºçš„å¹¿æœŸæ‰€æ–‡ä»¶ä»¥ä¿æŒå…¼å®¹æ€§
                            gfex_path = os.path.join(data_dir, exchange['filename'])
                            empty_data = {'è·³è¿‡è¯´æ˜': pd.DataFrame({'è¯´æ˜': ['å¹¿æœŸæ‰€æ•°æ®è·å–è¶…æ—¶ï¼Œå·²è‡ªåŠ¨è·³è¿‡']})}
                            with pd.ExcelWriter(gfex_path, engine='openpyxl') as writer:
                                for sheet_name, df in empty_data.items():
                                    df.to_excel(writer, sheet_name=sheet_name, index=False)
                            
                            continue
                        
                        # è·å–ç»“æœ
                        try:
                            status, data_dict = result_queue.get_nowait()
                            if status == 'error':
                                raise Exception(data_dict)
                        except queue.Empty:
                            st.warning("âš ï¸ å¹¿æœŸæ‰€æ•°æ®è·å–æ— å“åº”ï¼Œè‡ªåŠ¨è·³è¿‡")
                            self.max_retries = original_retries
                            continue
                            
                    finally:
                        self.max_retries = original_retries
                else:
                    # å…¶ä»–äº¤æ˜“æ‰€ä½¿ç”¨æ­£å¸¸çš„è·å–æ–¹å¼
                    data_dict = self.safe_akshare_call(exchange_func, **exchange['args'])
                
                end_time = time.time()
                elapsed_time = end_time - start_time
                
                if data_dict:
                    # ä¿å­˜æ•°æ®
                    save_path = os.path.join(data_dir, exchange['filename'])
                    with pd.ExcelWriter(save_path, engine='openpyxl') as writer:
                        for sheet_name, df in data_dict.items():
                            # æ¸…ç†sheetåç§°
                            clean_name = sheet_name[:31].replace("/", "-").replace("*", "")
                            df.to_excel(writer, sheet_name=clean_name, index=False)
                    
                    st.success(f"âœ… {exchange['name']} æ•°æ®è·å–æˆåŠŸ (è€—æ—¶: {elapsed_time:.1f}ç§’)")
                    success_count += 1
                else:
                    if exchange['name'] == 'å¹¿æœŸæ‰€':
                        st.warning(f"âš ï¸ {exchange['name']} æ•°æ®è·å–å¤±è´¥ï¼Œå·²è‡ªåŠ¨è·³è¿‡")
                    else:
                        st.warning(f"âš ï¸ {exchange['name']} æ•°æ®è·å–å¤±è´¥ï¼Œä½†ä¸å½±å“å…¶ä»–äº¤æ˜“æ‰€")
                    
            except Exception as e:
                error_msg = str(e)
                elapsed_time = time.time() - start_time
                
                if exchange['name'] == 'å¹¿æœŸæ‰€':
                    st.warning(f"âš ï¸ {exchange['name']} æ•°æ®è·å–å¤±è´¥ï¼Œå·²è‡ªåŠ¨è·³è¿‡: {error_msg}")
                    
                    # åˆ›å»ºç©ºçš„å¹¿æœŸæ‰€æ–‡ä»¶
                    gfex_path = os.path.join(data_dir, exchange['filename'])
                    empty_data = {'è·³è¿‡è¯´æ˜': pd.DataFrame({'è¯´æ˜': [f'å¹¿æœŸæ‰€æ•°æ®è·å–å¤±è´¥: {error_msg}']})}
                    with pd.ExcelWriter(gfex_path, engine='openpyxl') as writer:
                        for sheet_name, df in empty_data.items():
                            df.to_excel(writer, sheet_name=sheet_name, index=False)
                else:
                    st.warning(f"âš ï¸ {exchange['name']} æ•°æ®è·å–å¤±è´¥: {error_msg}")
                continue
            
            # æ·»åŠ è¯·æ±‚é—´éš”
            time.sleep(self.delay_between_requests)
        
        if progress_callback:
            progress_callback("æŒä»“æ•°æ®è·å–å®Œæˆ", 0.6)
        
        # å¦‚æœè‡³å°‘æœ‰3ä¸ªäº¤æ˜“æ‰€æˆåŠŸï¼Œå°±è®¤ä¸ºæˆåŠŸ
        if success_count >= 3:
            st.info(f"âœ… æˆåŠŸè·å– {success_count}/{total_exchanges} ä¸ªäº¤æ˜“æ‰€æ•°æ®ï¼Œå¯ä»¥è¿›è¡Œåˆ†æ")
            return True
        elif success_count > 0:
            st.warning(f"âš ï¸ ä»…è·å–åˆ° {success_count}/{total_exchanges} ä¸ªäº¤æ˜“æ‰€æ•°æ®ï¼Œåˆ†æç»“æœå¯èƒ½ä¸å®Œæ•´")
            return True
        else:
            st.error("âŒ æ‰€æœ‰äº¤æ˜“æ‰€æ•°æ®è·å–å¤±è´¥")
            return False

# å…¨å±€å®ä¾‹
cloud_fetcher = CloudDataFetcher() 
